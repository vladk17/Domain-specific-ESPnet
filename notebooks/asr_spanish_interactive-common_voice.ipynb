{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/carlfm01/120h-spanish-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "Total hours: 120h.\n",
    "\n",
    "Language: Spanish.\n",
    "\n",
    "Number of speakers: 17 without counting the collaborative audio books.\n",
    "\n",
    "Type of speech: Clean speech.\n",
    "\n",
    "A CSV file containing the audio file name and the aligned transcription.\n",
    "\n",
    "### Inspiration\n",
    "There's a lack of Spanish speech data to train or even to test under public domain. Test your own model and share your WER, spot bad transcriptions.\n",
    "\n",
    "### Provenance\n",
    "#### Sources\n",
    "https://librivox.org/\n",
    "\n",
    "Spanish books catalog in librivox are [here](https://librivox.org/search?primary_key=5&search_category=language&search_page=1&search_form=get_results)\n",
    "\n",
    "#### Collection methodology\n",
    "\n",
    "Automatically aligned the text with the Windows speech recognition,then as validation of the alignment used a Mozilla's DeepSpeech model using a few different language models.\n",
    "\n",
    "### Extra\n",
    "Collected by: Carlos Fonseca M @ https://github.com/carlfm01, probably by [this tool](https://github.com/carlfm01/librivox-tools)\n",
    "\n",
    "### License\n",
    "License : Public Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading \n",
    "#### Method 1\n",
    "export your cookies from your browser, when you logged in at kaggle and put your cookies.txt on your server. Then run:\n",
    "```\n",
    "mkdir data\n",
    "\n",
    "wget -x --load-cookies cookies.txt -P data -nH --cut-dirs=5 https://www.kaggle.com/carlfm01/120h-spanish-speech/download\n",
    "```\n",
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "#import subprocess\n",
    "#import tarfile\n",
    "#import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "#import IPython.display as ipd\n",
    "#from ipywidgets import interact\n",
    "#import ipywidgets as widgets\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%ls asr-spanish-v1-carlfm01\\audios\\0000df16-47ea-428f-8367-df2ce365d5c4.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%ls asr-spanish-v1-carlfm01\\asr-spanish-v1-carlfm01\\audios\\0000df16-47ea-428f-8367-df2ce365d5c4.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_name = os.path.join('/gong-asr/kaldi-12/Domain-specific-ESPnet','espnet','egs',\n",
    "                        'spanish_common_voice','asr1', 'raw_data', 'CommonVoiceSpanish', 'decompressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l {data_folder_name} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder_name = r'asr-spanish-v1-carlfm01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file_name= os.path.join(data_folder_name, 'clips', r'common_voice_es_18306544.mp3')\n",
    "description_file_name = os.path.join(data_folder_name,'train.tsv')\n",
    "\n",
    "# example_file_name= os.path.join(data_folder_name, 'clips', r'0000df16-47ea-428f-8367-df2ce365d5c4.wav')\n",
    "# description_file_name = os.path.join(data_folder_name,'files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l {description_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(description_file_name, index_col='wav_filename')\n",
    "\n",
    "df = pd.read_csv(description_file_name, sep='\\\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index) == len(set(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df.loc[df.index[0]]\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.path.join(*([data_folder_name]+df_raw.name.split('/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_by_df_raw(df_raw):\n",
    "#     print(df_raw)\n",
    "    audio, sample_rate = librosa.load(os.path.join(data_folder_name,'clips',df_raw.path))\n",
    "    plt.rcParams['figure.figsize'] = (15,7)\n",
    "    plt.title(f'Waveform of Audio Example: {example_file_name}')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "#     print(df_raw['wav_filesize'])\n",
    "    print(df_raw['sentence'])\n",
    "    _ = librosa.display.waveplot(audio)\n",
    "    return ipd.Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_by_df_raw(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def segment_by_df_raw(df_raw):\n",
    "#     audio, sample_rate = sf.read(os.path.join(*([data_folder_name]+df_raw.name.split('/'))))\n",
    "#     plt.rcParams['figure.figsize'] = (15,7)\n",
    "#     plt.title(f'Waveform of Audio Example: {example_file_name}')\n",
    "#     plt.ylabel('Amplitude')\n",
    "\n",
    "#     print(df_raw['wav_filesize'])\n",
    "#     print(df_raw['transcript'])\n",
    "#     _ = librosa.display.waveplot(audio)\n",
    "#     return ipd.Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment_by_df_raw(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_by_idx(idx):\n",
    "    return segment_by_df_raw(df.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(segment_by_idx, idx=widgets.IntSlider(min=0, max=df.shape[0]-1, step=1, value=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\"text\"__ contains the transcriptions of each utterance.<br>\n",
    "The first element is the utterance-id, which is an arbitrary text string. (but if you have speaker information in your setup, you should make the speaker-id a prefix of the utterance id; this is important for reasons relating to the sorting of these files). The rest of the line is the transcription of each sentence. You don't have to make sure that all words in this file are in your vocabulary; out of vocabulary words will get mapped to a word specified in the file data/lang/oov.txt.<br>\n",
    "Example:\n",
    "```\n",
    "s5# head -3 data/train/text\n",
    "sw02001-A_000098-001156 HI UM YEAH I'D LIKE TO TALK ABOUT HOW YOU DRESS FOR WORK AND\n",
    "sw02001-A_001980-002131 UM-HUM\n",
    "sw02001-A_002736-002893 AND IS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[:10];sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_series = sub_df['transcript']\n",
    "the_series = the_series.apply(lambda x: x.lower())\n",
    "the_series.index = [(lambda x: x+'_'+x)(ent.split('.')[0].split('/')[1]) for ent in sub_df.index]\n",
    "the_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_fix(the_df, the_file_name):\n",
    "    the_df.to_csv(the_file_name, sep =' ', header = False, quotechar = '@')\n",
    "    with open (the_file_name, 'r') as fr:\n",
    "        the_file_str = fr.read()\n",
    "        fixed_file_str = re.sub('@','',the_file_str)\n",
    "    with open (the_file_name, 'w') as fw:\n",
    "        fw.write(fixed_file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_fix(the_series.sort_index(), os.path.join('data','sub_text'))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"wav.scp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format:\n",
    "```\n",
    "<recording-id> <extended-filename>\n",
    "```\n",
    "where \"extended-filename\" may be an actual filename or a command that extracts a wav-format file. The pipe symbol on the end of the extended-filename specifies that it is to be interpreted as a pipe. If the \"segments\" file does not exist, the first token on each line of \"wav.scp\" file is just the utterance id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_wav_scp_df = pd.DataFrame(list(sub_df.index), index = [ent.split('.')[0].split('/')[1] for ent in sub_df.index])\n",
    "sub_wav_scp_df.index = [(lambda x: x+'_'+x)(ent) for ent in sub_wav_scp_df.index]\n",
    "sub_wav_scp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_fix(sub_wav_scp_df.sort_index(), os.path.join('data','sub_wav.scp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"utt2spk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format\n",
    "```\n",
    "<utterance-id> <speaker-id>\n",
    "```\n",
    "If you have no information at all about the speaker identities, you can just make the speaker-ids the same as the utterance-ids,so the format of the file would be just `<utterance-id> <utterance-id>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utts = [ent.split('.')[0].split('/')[1] for ent in sub_df.index]\n",
    "sub_utt2spk_df = pd.DataFrame(utts, index = utts)\n",
    "sub_utt2spk_df.index = [(lambda x: x+'_'+x)(ent) for ent in sub_utt2spk_df.index]\n",
    "sub_utt2spk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_fix(sub_utt2spk_df.sort_index(), os.path.join('data','sub_utt2spk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_spk2utt_df = pd.DataFrame(utts, index = utts)\n",
    "sub_spk2utt_df = sub_spk2utt_df.applymap(lambda x: x+'_'+x)\n",
    "sub_spk2utt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_fix(sub_spk2utt_df.sort_index(), os.path.join('data','sub_spk2utt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_num = '1234'\n",
    "# chap_num = '123456'\n",
    "\n",
    "# path = Path(os.path.join(f\"{book_num}\",f\"{chap_num}\"))\n",
    "# path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = path.joinpath(f'{book_num}-{chap_num}.trans.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder_name = r'asr-spanish-v1-carlfm01'\n",
    "# description_file_name = os.path.join(data_folder_name,'files.csv')\n",
    "# df = pd.read_csv(description_file_name, index_col='wav_filename')\n",
    "# sub_df = df[:10];sub_df\n",
    "\n",
    "# book_num = '1234'\n",
    "# chap_num = '123456'\n",
    "# path = Path(os.path.join(f\"{book_num}\",f\"{chap_num}\"))\n",
    "# path.mkdir(parents=True, exist_ok=True)\n",
    "# file_path = path.joinpath(f'{book_num}-{chap_num}.trans.txt')\n",
    "\n",
    "# path = Path(os.path.join(f\"{book_num}\",f\"{chap_num}\"))\n",
    "# path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# with open(file_path, 'w') as fw:\n",
    "#     for idx in range(sub_df.shape[0]):        \n",
    "#         df_raw = sub_df.iloc[idx]\n",
    "#         #print(df_raw)\n",
    "#         fw.write(f'{book_num}-{chap_num}-{idx:04}'+' '+df_raw['transcript'].upper())\n",
    "#         fw.write('\\n')\n",
    "#         source_path = Path(os.path.join(*([data_folder_name]+df_raw.name.split('/'))))\n",
    "#         #print(source_path)\n",
    "#         #print(source_path.exists ())\n",
    "#         destination_path = Path(os.path.join(book_num,chap_num,f'{book_num}-{chap_num}-{idx:04}'+'.wav'))\n",
    "#         #destination_path.touch()\n",
    "#         print(destination_path)\n",
    "#         destination_path.write_bytes(source_path.read_bytes())\n",
    "#         with open(source_path, 'rb') as src, open(destination_path, 'wb') as dst: dst.write(src.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('AWS_SPEAKERS.TXT') as fr:\n",
    "#     speakers_str = fr.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(speakers_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utt2dur_df = pd.read_csv('train_utt2dur', sep= ' ', header = None, names=['utt', 'dur', 'na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utt2dur_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_utt2dur_df['na'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utt2dur_df['dur'].sum()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utt2dur_df['dur'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
