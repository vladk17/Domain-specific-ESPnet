{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<style>.container {width:95% !important; }</stype>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://voice.mozilla.org/en/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "Total hours: ? h.\n",
    "\n",
    "Language: Spanish.\n",
    "\n",
    "Number of speakers: ???.\n",
    "\n",
    "Type of speech: ??? # Clean speech.\n",
    "\n",
    "\n",
    "#### Collection methodology\n",
    "\n",
    "????\n",
    "\n",
    "### Extra\n",
    "Collected by: \n",
    "\n",
    "### License\n",
    "License : Public Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading \n",
    "#### Method \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "#import subprocess\n",
    "#import tarfile\n",
    "#import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "#import IPython.display as ipd\n",
    "#from ipywidgets import interact\n",
    "#import ipywidgets as widgets\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%ls asr-spanish-v1-carlfm01\\audios\\0000df16-47ea-428f-8367-df2ce365d5c4.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%ls asr-spanish-v1-carlfm01\\asr-spanish-v1-carlfm01\\audios\\0000df16-47ea-428f-8367-df2ce365d5c4.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_folder_name = os.path.join('/gong-asr/kaldi-12/Domain-specific-ESPnet','espnet','egs',\n",
    "                        'spanish_common_voice','asr1')\n",
    "\n",
    "data_folder_name = os.path.join(egg_folder_name, 'raw_data', 'CommonVoiceSpanish', 'decompressed')\n",
    "\n",
    "kaldi_ready_data_folder_name = os.path.join(egg_folder_name, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l {data_folder_name} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_file_name = os.path.join(data_folder_name,'train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l {description_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(description_file_name, sep='\\\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index) == len(set(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df.loc[df.index[0]]\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_by_df_raw(df_raw):\n",
    "    audio, sample_rate = librosa.load(os.path.join(data_folder_name,'clips',df_raw.path))\n",
    "    plt.rcParams['figure.figsize'] = (15,7)\n",
    "    plt.title(f'Waveform of Audio Example: {df_raw[\"path\"]}')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    print(df_raw['sentence'])\n",
    "    print(f'sample_rate: {sample_rate}')\n",
    "    _ = librosa.display.waveplot(audio)\n",
    "    return ipd.Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_by_df_raw(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_by_idx(idx):\n",
    "    return segment_by_df_raw(df.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(segment_by_idx, idx=widgets.IntSlider(min=0, max=df.shape[0]-1, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peth = '/espnet/egs/spanish_common_voice/asr1/raw_data/CommonVoiceSpanish/decompressed/clips/common_voice_es_19499893.mp3'\n",
    "file_name = 'common_voice_es_19499893.mp3'\n",
    "def show_audio(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(os.path.join(data_folder_name,'clips',file_name))\n",
    "        plt.rcParams['figure.figsize'] = (15,7)\n",
    "    #     plt.title(f'Waveform of Audio Example: {df_raw[\"path\"]}')\n",
    "        plt.ylabel('Amplitude')\n",
    "        _ = librosa.display.waveplot(audio)\n",
    "        res = ipd.Audio(audio, rate=sample_rate)    \n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "        res = None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_audio(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = 'test'\n",
    "kaldi_ready_md_folder = os.path.join(kaldi_ready_data_folder_name, 'test')\n",
    "kaldi_ready_audio_folder = os.path.join(kaldi_ready_data_folder_name, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l {kaldi_ready_md_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n5 {os.path.join(kaldi_ready_md_folder, 'wav.scp')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n5 {os.path.join(kaldi_ready_md_folder, 'text')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavscp_df = pd.read_csv(os.path.join(kaldi_ready_md_folder, 'wav.scp'), sep=' ',header=None)\\\n",
    ".set_index(0)\n",
    "wavscp_df.columns = ['wav']\n",
    "wavscp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(kaldi_ready_md_folder, 'text'), 'r') as text_fd:\n",
    "    text_str = text_fd.read()\n",
    "text_df = pd.DataFrame(np.array([(lambda x: (x[0], ' '.join(x[1:])))(ent.split(' ')) for ent in text_str.split('\\n') if ''!=ent])).set_index(0)\n",
    "text_df.columns = ['text']\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(text_df.index == wavscp_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = wavscp_df.join(text_df)\n",
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_by_parsed_df_raw(df_raw):\n",
    "    audio, sample_rate = sf.read(os.path.join(egg_folder_name, df_raw.wav))\n",
    "    plt.rcParams['figure.figsize'] = (15,7)\n",
    "    plt.title(f'Waveform of Audio Example: {df_raw[\"wav\"]}')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    print(df_raw['text'])\n",
    "    print(f'sample_rate: {sample_rate}')                            \n",
    "    _ = librosa.display.waveplot(audio)\n",
    "    return ipd.Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_segment_by_idx(idx):\n",
    "    return segment_by_parsed_df_raw(parsed_df.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l /gong-asr/kaldi-12/Domain-specific-ESPnet/espnet/egs/spanish_common_voice/asr1/data/train/downloads/comvoice/common_voice_es_19698530.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(parsed_segment_by_idx, idx=widgets.IntSlider(min=0, max=parsed_df.shape[0]-1, step=1, value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_local_path = 'dump/train_set/deltafalse/data_unigram5000.json'\n",
    "train_dev_json_local_path = 'dump/train_dev/deltafalse/data_unigram5000.json'\n",
    "test_json_local_path = 'dump/test/deltafalse/data_unigram5000.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = json.loads(open(os.path.join(egg_folder_name, train_json_local_path),'r').read())\n",
    "train_dev_dict = json.loads(open(os.path.join(egg_folder_name, train_dev_json_local_path),'r').read())\n",
    "test_dict = json.loads(open(os.path.join(egg_folder_name, test_json_local_path),'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(train_dict['utts'].keys())))\n",
    "print(len(list(train_dev_dict['utts'].keys())))\n",
    "print(len(list(test_dict['utts'].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_dict['utts'].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict['utts'][list(train_dict['utts'].keys())[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict['utts'][list(train_dict['utts'].keys())[0]]['utt2spk'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spks = (lambda x: {x['utts'][k]['utt2spk'] for k in x['utts'].keys()})(train_dict)\n",
    "len(train_spks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_spks = (lambda x: {x['utts'][k]['utt2spk'] for k in x['utts'].keys()})(train_dev_dict)\n",
    "len(train_dev_spks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spks = (lambda x: {x['utts'][k]['utt2spk'] for k in x['utts'].keys()})(test_dict)\n",
    "len(test_spks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check there is no intersection of speekers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.intersect1d(train_spks, train_dev_spks)))\n",
    "print(len(np.intersect1d(train_spks, test_spks)))\n",
    "print(len(np.intersect1d(train_dev_spks, test_spks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_shapes = (lambda x: [x['utts'][k]['input'][0]['shape'] for k in x['utts'].keys()])(train_dict)\n",
    "train_output_shapes = (lambda x: [x['utts'][k]['output'][0]['shape'] for k in x['utts'].keys()])(train_dict)\n",
    "print(set(np.array(train_input_shapes).T[1])) # should be correspondent to 80 fbanks \n",
    "print(set(np.array(train_output_shapes).T[1])) # should be correspondent to 5000 subwords in the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_input_shapes = (lambda x: [x['utts'][k]['input'][0]['shape'] for k in x['utts'].keys()])(train_dev_dict)\n",
    "train_dev_output_shapes = (lambda x: [x['utts'][k]['output'][0]['shape'] for k in x['utts'].keys()])(train_dev_dict)\n",
    "print(set(np.array(train_dev_input_shapes).T[1])) # should be correspondent to 80 fbanks \n",
    "print(set(np.array(train_dev_output_shapes).T[1])) # should be correspondent to 5000 subwords in the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_shapes = (lambda x: [x['utts'][k]['input'][0]['shape'] for k in x['utts'].keys()])(test_dict)\n",
    "test_output_shapes = (lambda x: [x['utts'][k]['output'][0]['shape'] for k in x['utts'].keys()])(test_dict)\n",
    "print(set(np.array(test_input_shapes).T[1])) # should be correspondent to 80 fbanks \n",
    "print(set(np.array(test_output_shapes).T[1])) # should be correspondent to 5000 subwords in the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_file_list = glob.glob(str(os.path.join(egg_folder_name, \"exp/train_set_pytorch_train/results/att_ws/\"))+'*encoder*')\n",
    "decoders_file_list = glob.glob(str(os.path.join(egg_folder_name, \"exp/train_set_pytorch_train/results/att_ws/\"))+'*decoder*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_file_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls -l {os.path.join(egg_folder_name, \"exp/train_set_pytorch_train/results/att_ws/\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoders_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decoders_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Image(file_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_encoder_file_by_idx(idx):\n",
    "    print(encoders_file_list[idx].split('/')[-1])\n",
    "    return Image(encoders_file_list[idx])\n",
    "\n",
    "def show_decoder_file_by_idx(idx):\n",
    "    print(decoders_file_list[idx].split('/')[-1])\n",
    "    return Image(decoders_file_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_encoder_file_by_idx, idx=widgets.IntSlider(min=0, max=len(encoders_file_list)-1, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_decoder_file_by_idx, idx=widgets.IntSlider(min=0, max=len(decoders_file_list)-1, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(egg_folder_name,'exp/train_set_pytorch_train/train.log'), 'r') as rfd:\n",
    "    train_log_str = rfd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_log_str[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll /espnet/tools/venv/lib/python3.7/site-packages/librosa/util/decorators.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_lines = [ent for ent in train_log_str.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(' +',',',[ent for ent in train_log_str.split('\\n') if 'iteration' in ent][0]).split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [train_log_lines[idx] for idx, ent in enumerate(train_log_lines[2:]) if 15 == len(re.sub(' +',',',ent).split(','))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [ent for ent in train_log_str.split('\\n') if not 'length' in ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# acoustic_learning_outputs = [ent for ent in train_log_str.split('\\n') if 'epoch' in ent]\n",
    "# acoustic_learning_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[train_log_lines[idx+2] for idx, ent in enumerate(train_log_lines[2:]) if not '2020-06-28' in ent and '\\x1b[J' in ent and not 'total' in ent]\n",
    "[' '.join(re.sub(' +',',',[ent for ent in train_log_str.split('\\n') if 'iteration' in ent][0]).split(',')[1:])] + \\\n",
    "[' '.join(re.sub(' +',',',ent).split(',')[1:]) for idx, ent in enumerate(train_log_lines[2:]) if not '2020-06-28' in ent and '\\x1b[J' in ent and not 'total' in ent \\\n",
    " and 15 == len(re.sub(' +',',',ent).split(',')[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_stats_df = pd.DataFrame(np.array([re.sub(' +',',',ent).split(',')[1:-1] for idx, ent in enumerate(train_log_lines[2:]) if not '2020-06-28' in ent and '\\x1b[J' in ent and not 'total' in ent \\\n",
    " and 15 == len(re.sub(' +',',',ent).split(',')[1:])]), columns=re.sub(' +',',',[ent for ent in train_log_str.split('\\n') if 'iteration' in ent][0]).split(',')[1:]).set_index('iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_stats_df.drop(labels=['elapsed_time','main/acc','validation/main/acc', 'validation/main/cer', 'validation/main/wer', 'main/cer_ctc','validation/main/cer_ctc'],axis=1).applymap(float)\\\n",
    ".plot(title='\"loss\"',figsize=(15,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_stats_df.drop(labels=['elapsed_time'],axis=1)[['main/acc','validation/main/acc']].applymap(float)\\\n",
    ".plot(title='\"accuracy\"',figsize=(15,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_stats_df.drop(labels=['elapsed_time'],axis=1)[['validation/main/cer', 'main/cer_ctc','validation/main/cer_ctc']].applymap(float)\\\n",
    ".plot(title='\"cer\"',figsize=(15,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_stats_df.drop(labels=['elapsed_time'],axis=1)[['validation/main/wer']].applymap(float)\\\n",
    ".plot(title='\"validation/main/wer\"',figsize=(15,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(train_log_lines[idx-1],re.sub(' +',',',ent).split(',')) for idx, ent in enumerate(train_log_lines) if 'validation/main/loss_att' in ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [(train_log_lines[idx-1],re.sub(' +',',',ent).split(',')) for idx, ent in enumerate(train_log_lines) if \\\n",
    "#  9 == len(re.sub(' +',',',ent).split(','))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(' +',',',[ent for ent in train_log_str.split('\\n') if 'iteration' in ent][0]).split(',')[1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([re.sub(' +',',',ent).split(',')[1:-1] for idx, ent in enumerate(train_log_lines[2:]) if not '2020-06-28' in ent and '\\x1b[J' in ent and not 'total' in ent \\\n",
    " and 8 == len(re.sub(' +',',',ent).split(',')[1:])])#columns=re.sub(' +',',',[ent for ent in train_log_str.split('\\n') if 'iteration' in ent][0]).split(',')[1:8]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[(train_log_lines[idx +1][len('\\x1b[J'):], train_log_lines[idx +2], train_log_lines[idx +3], train_log_lines[idx +4]\n",
    "#   , \n",
    "#   train_log_lines[idx +7], train_log_lines[idx +14]\n",
    " ) for idx, ent in enumerate(train_log_lines[2:]) if 'this epoch' in ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acoustic_learning_outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerated_acoustic_learning_outputs = [(idx, ent) for (idx, ent) in enumerate(train_log_str.split('\\n')) if 'epoch' in ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [(train_log_lines[ent[0]-1], ent[1], train_log_lines[ent[0]+1], train_log_lines[ent[0]+2]) for ent in enumerated_acoustic_learning_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_file_list = glob.glob(str(os.path.join(egg_folder_name)+'/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ent for ent in dir_file_list if Path(ent).is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_dirs_list = [ent1 for ent1 in [ent for ent in dir_file_list if Path(ent).is_dir()] if not ('downloads' in ent1 or 'raw_data' in ent1)]\n",
    "dir_dirs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = Path(egg_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(target_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_path = (lambda x: Path(str(os.path.join(list(x.parts[:-2])+[x.parts[-2]+'_backup1']))))(Path(egg_folder_name))\n",
    "# target_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = (lambda x: Path(os.path.join(*tuple(list(x.parts[:-2])+[x.parts[-2]+'_backup1', x.parts[-1]]))))(Path(egg_folder_name))\n",
    "target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_path.mkdir(exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ent in dir_file_list:\n",
    "#     if Path(ent).is_file():\n",
    "#         ! cp {ent} {target_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ent in dir_file_list:\n",
    "#     if Path(ent).is_dir() and not ('downloads' in ent or 'raw_data' in ent):\n",
    "#         ! cp -r {ent} {target_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files_list = glob.glob(str(os.path.join(data_folder_name,'clips')+\"/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timelingth_raw(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name)\n",
    "    return (audio.shape[0]/sample_rate)\n",
    "#     plt.rcParams['figure.figsize'] = (15,7)\n",
    "#     plt.title(f'Waveform of Audio Example: {df_raw[\"path\"]}')\n",
    "#     plt.ylabel('Amplitude')\n",
    "\n",
    "#     print(df_raw['sentence'])\n",
    "#     print(f'sample_rate: {sample_rate}')\n",
    "#     _ = librosa.display.waveplot(audio)\n",
    "#     return ipd.Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelingth_raw(raw_files_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation\n",
    "148372 * 3/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the exact calculation of the aggregated time \n",
    "# the rate is ~2 iterations in a second => it is going to take 20 hours\n",
    "\n",
    "# total_time_length = 0\n",
    "# for file in tqdm_notebook(raw_files_list):\n",
    "#     total_time_length +=timelingth_raw(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
